https://www.coursera.org/learn/hadoop/home/welcome

### 
* Apache Hadoop is a open source software framework for storage and large scale processing of the data-sets and clusters on commodity hardware. 
* Hadoop moves computation to data, scalability at its core, Reliability - Hardware failures are handled automatically, keep all data
* HDFS - Hadoop Distributed File System
* Yarn Hadoop 2.0 enhances the power of a hadoop compute cluster
* Apache Sqoop is a tool designed for efficiently transferring bulk data between Apache Hadoop and structured datastores such as relational databases
* Spark - Data Analytics platform for in-memory computing. Fast and general engine for large-scale data processing. Scala language


